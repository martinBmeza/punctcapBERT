# Script de Generaci√≥n de Predicciones para Test CSV (Versi√≥n Optimizada)

Este script (`generate_test_predictions.py`) genera predicciones para completar un CSV de test usando un modelo entrenado. **NUEVA VERSI√ìN**: Replica exactamente la l√≥gica del script de preprocesamiento para m√°xima compatibilidad.

## ‚ú® Caracter√≠sticas Mejoradas

### **üîÑ L√≥gica de Preprocesamiento Replicada**
- Usa `split_words_and_punct()` y `build_word_level_labels()` igual que en entrenamiento
- Tokenizaci√≥n id√©ntica con `BertTokenizerFast` y `is_split_into_words=True`
- Chunks de **64 tokens** con stride de **32** (exactamente como entrenamiento)
- Normalizaci√≥n de palabras con `normalize_word_for_input()`

### **üìä Mapeo Correcto de Clases**
Verificado contra `src/data/utils.py`:
- **Puntuaci√≥n inicial**: `{0: '', 1: '¬ø'}`  (incluye ¬° en preprocesamiento)
- **Puntuaci√≥n final**: `{0: '', 1: ',', 2: '.', 3: '?'}` (clase 2 incluye ! ‚Üí punto)
- **Capitalizaci√≥n**: Mantiene valores num√©ricos 0-3

### **üéØ Promediado de Predicciones Solapadas**
- Los chunks con stride generan solapamiento entre tokens
- Las predicciones se promedian para tokens que aparecen en m√∫ltiples chunks
- Resultado final m√°s robusto y consistente

## Uso B√°sico

```bash
# Generar predicciones usando archivos por defecto
python generate_test_predictions.py \
    --model_cfg "configs/wiki_BiLSTM.yaml" \
    --model_pt "results/wiki_BiLSTM-20251129_052431/best_model.pt"

# O usando el script de bash
bash run_generate_test_predictions.sh
```

## Argumentos CLI

- `--model_cfg`: Ruta al archivo de configuraci√≥n YAML del modelo (**requerido**)
- `--model_pt`: Ruta al archivo .pt del modelo entrenado (**requerido**)
- `--test_csv`: Ruta al CSV de test (default: `data/raw/datos_test.csv`)
- `--output_dir`: Directorio de salida (default: `data/processed`)
- `--tokenizer_name`: Nombre del tokenizer (default: `bert-base-multilingual-cased`)

## Formato de Entrada

El CSV de test debe tener las columnas:
```
instancia_id,token_id,token,punt_inicial,punt_final,capitalizaci√≥n
```

Donde las √∫ltimas 3 columnas pueden estar vac√≠as (se completar√°n con las predicciones).

## Formato de Salida

El script genera un archivo `datos_test_{config_name}.csv` con las mismas columnas pero completadas:

- `punt_inicial`: '' (sin puntuaci√≥n) o '¬ø' (puntuaci√≥n inicial)
- `punt_final`: '' (sin puntuaci√≥n), ',' (coma), '.' (punto), o '?' (interrogaci√≥n)  
- `capitalizaci√≥n`: 0-3 (diferentes tipos de capitalizaci√≥n)

## Mapeo de Predicciones

### Puntuaci√≥n Inicial
- Clase 0 ‚Üí '' (cadena vac√≠a, sin puntuaci√≥n)
- Clase 1 ‚Üí '¬ø' (signo de interrogaci√≥n inicial)

### Puntuaci√≥n Final  
- Clase 0 ‚Üí '' (cadena vac√≠a, sin puntuaci√≥n)
- Clase 1 ‚Üí ',' (coma)
- Clase 2 ‚Üí '.' (punto)
- Clase 3 ‚Üí '?' (signo de interrogaci√≥n final)

## Ejemplo de Salida

```
instancia_id  token    punt_inicial  punt_final  capitalizaci√≥n
0            la       ""            ""          1
0            cuesti√≥n "¬ø"           ""          0
0            es       ""            "?"         0
0            que      ""            ","         0
```

## Funcionamiento Interno Mejorado

1. **Procesamiento por instancia**: Agrupa tokens por `instancia_id`
2. **Reconstrucci√≥n de texto**: Une tokens para recrear texto original
3. **Preprocesamiento replicado**: 
   - `split_words_and_punct()` ‚Üí separar palabras y puntuaci√≥n
   - `build_word_level_labels()` ‚Üí crear etiquetas a nivel palabra
   - `normalize_word_for_input()` ‚Üí normalizar palabras
4. **Tokenizaci√≥n BERT exacta**: Mismo proceso que entrenamiento
5. **Chunking con stride**: Ventanas de 64 tokens con solapamiento de 32
6. **Predicci√≥n del modelo**: Inferencia en cada chunk
7. **Mapeo inverso**: De tokens de chunks de vuelta a CSV original
8. **Promediado**: Combina predicciones solapadas para mayor robustez
9. **Conversi√≥n de clases**: Mapea n√∫meros a signos de puntuaci√≥n

## Configuraci√≥n de Tokens

```python
max_len = 64      # Igual que entrenamiento
stride = 32       # 50% de solapamiento para robustez
```

## Mapeo de Clases Verificado

Basado en `src/data/utils.py`, las clases se mapean correctamente:

```python
# Puntuaci√≥n inicial (¬ø y ¬° se marcan como clase 1)
punt_inicial_map = {0: '', 1: '¬ø'}

# Puntuaci√≥n final (! se mapea a clase 2 como punto)
punt_final_map = {0: '', 1: ',', 2: '.', 3: '?'}
```

## Manejo de Errores

- Si `transformers` no est√° disponible, genera predicciones aleatorias como demostraci√≥n
- Si el texto es muy largo, lo divide en chunks y procesa por partes
- Maneja instancias de diferentes longitudes autom√°ticamente

## Archivos de Salida

- `datos_test_{config_name}.csv`: CSV completado con predicciones
- Estad√≠sticas en consola con resumen de predicciones generadas
- Muestra de los primeros resultados para verificaci√≥n

## Ejemplo de Uso Completo

```bash
python generate_test_predictions.py \
    --model_cfg "configs/baselineRNN.yaml" \
    --model_pt "results/baseline_experiment/best_model.pt" \
    --test_csv "data/raw/datos_test.csv" \
    --output_dir "data/results" \
    --tokenizer_name "bert-base-multilingual-cased"
```

Esto generar√°: `data/results/datos_test_baselineRNN.csv`